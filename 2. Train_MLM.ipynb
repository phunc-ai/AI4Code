{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLM_Training.ipynb","provenance":[],"background_execution":"on"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c5acc3699a2a4d63987a42d3d2d435ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a52427659d0b4c3bb2962d3adc731eb9","IPY_MODEL_75fa859dcaaf44f896506766074f00c0","IPY_MODEL_e7e130c79119497f9616633c5f31418a"],"layout":"IPY_MODEL_03a35d125b4b4cff8255590b2be52ed6"}},"a52427659d0b4c3bb2962d3adc731eb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cbbd720c4e846bfb3d3431b4e15f81b","placeholder":"â€‹","style":"IPY_MODEL_98680473f3994806b54ab66777c0e66b","value":"Downloading: 100%"}},"75fa859dcaaf44f896506766074f00c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f28e02e7ab4c444a90392aff11d41e62","max":498627950,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea3ae24f361c483db19a959ca4fe6560","value":498627950}},"e7e130c79119497f9616633c5f31418a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cee9c1684234a1d95fa4143e7b89020","placeholder":"â€‹","style":"IPY_MODEL_be61cbb643d14c1abb7c7205d247109e","value":" 476M/476M [00:12&lt;00:00, 50.1MB/s]"}},"03a35d125b4b4cff8255590b2be52ed6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cbbd720c4e846bfb3d3431b4e15f81b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98680473f3994806b54ab66777c0e66b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f28e02e7ab4c444a90392aff11d41e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea3ae24f361c483db19a959ca4fe6560":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3cee9c1684234a1d95fa4143e7b89020":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be61cbb643d14c1abb7c7205d247109e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93e3230ac43441d3bc34e05b04fa2bbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2084414a83bd44e9871d6c69c6042a7a","IPY_MODEL_5cf62b6149ba4edc845e97da9749a704","IPY_MODEL_89e8eb21a26847a7b9542d71b821a250"],"layout":"IPY_MODEL_3655aaf72a4f4e7284a15227059b9dfa"}},"2084414a83bd44e9871d6c69c6042a7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e51fa414b20c4407b239124a1e7f518e","placeholder":"â€‹","style":"IPY_MODEL_93e9cf7364e749adadbb490746aa523a","value":"Skipping the first batches: 100%"}},"5cf62b6149ba4edc845e97da9749a704":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84660ae7e8cd44bfbb0b306214420b68","max":35130,"min":0,"orientation":"horizontal","style":"IPY_MODEL_767456caa6cc493ab784ad4738748fde","value":35130}},"89e8eb21a26847a7b9542d71b821a250":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dd1fe59fbb64ab4a6dfd2096c6053be","placeholder":"â€‹","style":"IPY_MODEL_5140b7360b9b44d1a91b224cd9bbe305","value":" 35130/35130 [37:09&lt;00:00, 15.53it/s]"}},"3655aaf72a4f4e7284a15227059b9dfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e51fa414b20c4407b239124a1e7f518e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93e9cf7364e749adadbb490746aa523a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84660ae7e8cd44bfbb0b306214420b68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"767456caa6cc493ab784ad4738748fde":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4dd1fe59fbb64ab4a6dfd2096c6053be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5140b7360b9b44d1a91b224cd9bbe305":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s42tMp53qZ2_","executionInfo":{"status":"ok","timestamp":1653959326277,"user_tz":-420,"elapsed":5,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"14c88fee-1e3d-4999-ac14-a6a596ca2529"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue May 31 01:08:45 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    42W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["!pip install -q transformers"],"metadata":{"id":"kFKsESkaqgB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, sys\n","from pathlib import Path\n","from tqdm.notebook import tqdm\n","\n","\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from transformers import RobertaForMaskedLM, RobertaTokenizerFast, RobertaTokenizer\n","from transformers import LineByLineTextDataset, DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments"],"metadata":{"id":"ZD0DJgw0rzgV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load clean dataset"],"metadata":{"id":"nV_DYYMctpuf"}},{"cell_type":"code","source":["# df = pd.read_pickle('/content/drive/MyDrive/NLP/AI4Code/dataset/exp_5/clean_dataset.pkl')\n","# df"],"metadata":{"id":"ktuCECZLtkoK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare dataset for Mask Language Model"],"metadata":{"id":"2q6Wup0IuDzQ"}},{"cell_type":"code","source":["# df_test = df.loc[:976].copy()\n","# df_test.tail()"],"metadata":{"id":"sdJ6mU4fNt16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open('/content/drive/MyDrive/NLP/AI4Code/dataset/exp_5/corpus_mlm_codebert.txt', 'w') as f:\n","#     for id, item in tqdm(df.groupby('id')):\n","#         df_markdown = item[item['cell_type'] == 'markdown']\n","#         df_code = item[item['cell_type'] == 'code']\n","\n","#         matched_cid = []\n","#         for cid, source, rank in df_markdown[['cell_id', 'source', 'rank']].values:\n","#             cell_source = df_code[df_code['rank'] == (rank+1)]\n","            \n","#             if len(cell_source):\n","#                 sentence = source + \"</s>\" + cell_source.source.values[0]\n","#                 matched_cid.append(cid)\n","#                 matched_cid.append(cell_source['cell_id'].values[0])\n","#                 f.write(sentence+'\\n')\n","        \n","#         for cid, source, ctype in item[['cell_id', 'source', 'cell_type']].values:\n","#             if cid not in matched_cid:\n","#                 if ctype == 'markdown':\n","#                     sentence = source + \"</s>\" +  ''\n","#                 elif ctype == 'code':\n","#                     sentence = '' + \"</s>\" +  source\n","#                 else:\n","#                     raise Exception\n","#                 f.write(sentence+'\\n')"],"metadata":{"id":"Xr7_ZGVvt_uF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train model\n","\n"],"metadata":{"id":"NxjUuO_cw10s"}},{"cell_type":"code","source":["tokenizer = RobertaTokenizerFast.from_pretrained(\"microsoft/codebert-base\", do_lower_case=True)\n","# tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\", do_lower_case=True)\n","model = RobertaForMaskedLM.from_pretrained(\"microsoft/codebert-base\")"],"metadata":{"id":"xTyc4vQjwPig","executionInfo":{"status":"ok","timestamp":1653959348570,"user_tz":-420,"elapsed":16260,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["c5acc3699a2a4d63987a42d3d2d435ba","a52427659d0b4c3bb2962d3adc731eb9","75fa859dcaaf44f896506766074f00c0","e7e130c79119497f9616633c5f31418a","03a35d125b4b4cff8255590b2be52ed6","9cbbd720c4e846bfb3d3431b4e15f81b","98680473f3994806b54ab66777c0e66b","f28e02e7ab4c444a90392aff11d41e62","ea3ae24f361c483db19a959ca4fe6560","3cee9c1684234a1d95fa4143e7b89020","be61cbb643d14c1abb7c7205d247109e"]},"outputId":"015229f6-64a5-4c21-893a-28013dc98af5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5acc3699a2a4d63987a42d3d2d435ba"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["text = \"all image have same shape</s>\"\n","code_tokens=tokenizer.tokenize(text, add_special_tokens=True)\n","code_tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_-ii8WuXQjT","executionInfo":{"status":"ok","timestamp":1653959348571,"user_tz":-420,"elapsed":15,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"2bd5a94d-be74-4605-ba21-3ea6940cdf88"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s>', 'all', 'Ä image', 'Ä have', 'Ä same', 'Ä shape', '</s>', '</s>']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",")\n","\n","dataset = LineByLineTextDataset(\n","    tokenizer=tokenizer,\n","    file_path = '/content/drive/MyDrive/NLP/AI4Code/dataset/exp_5/corpus_mlm_codebert.txt',\n","    block_size = 128\n",")\n","\n","print(\"No. of lines: \", len(dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2bdQ9aExR4c","executionInfo":{"status":"ok","timestamp":1653959729321,"user_tz":-420,"elapsed":380761,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"6f650c68-6c60-4e07-f20f-a498595d4b26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["No. of lines:  4791671\n"]}]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir = '/content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm',\n","    overwrite_output_dir=True,\n","    num_train_epochs=5,\n","    per_device_train_batch_size=128,\n","    per_device_eval_batch_size=128,\n","    logging_first_step=True,\n","    logging_steps=5000,\n","    save_steps=10000,\n",")"],"metadata":{"id":"uh5QIAWcx7XL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=dataset,\n",")\n","\n","# trainer.train()\n","trainer.train(resume_from_checkpoint = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["93e3230ac43441d3bc34e05b04fa2bbe","2084414a83bd44e9871d6c69c6042a7a","5cf62b6149ba4edc845e97da9749a704","89e8eb21a26847a7b9542d71b821a250","3655aaf72a4f4e7284a15227059b9dfa","e51fa414b20c4407b239124a1e7f518e","93e9cf7364e749adadbb490746aa523a","84660ae7e8cd44bfbb0b306214420b68","767456caa6cc493ab784ad4738748fde","4dd1fe59fbb64ab4a6dfd2096c6053be","5140b7360b9b44d1a91b224cd9bbe305"]},"id":"_XyxsOjQx8fl","outputId":"86577d30-541d-4f20-b59d-dd08327434e4","executionInfo":{"status":"error","timestamp":1653978740921,"user_tz":-420,"elapsed":5415038,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Loading model from /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-110000).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 4791671\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 187175\n","  Continuing training from checkpoint, will skip to saved global_step\n","  Continuing training from epoch 2\n","  Continuing training from global step 110000\n","  Will skip the first 2 epochs then the first 35130 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93e3230ac43441d3bc34e05b04fa2bbe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/35130 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='143904' max='187175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [143904/187175 3:08:52 < 4:01:04, 2.99 it/s, Epoch 3.84/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>115000</td>\n","      <td>0.823800</td>\n","    </tr>\n","    <tr>\n","      <td>120000</td>\n","      <td>0.807500</td>\n","    </tr>\n","    <tr>\n","      <td>125000</td>\n","      <td>0.797500</td>\n","    </tr>\n","    <tr>\n","      <td>130000</td>\n","      <td>0.793000</td>\n","    </tr>\n","    <tr>\n","      <td>135000</td>\n","      <td>0.785600</td>\n","    </tr>\n","    <tr>\n","      <td>140000</td>\n","      <td>0.777800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Saving model checkpoint to /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-120000\n","Configuration saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-120000/config.json\n","Model weights saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-120000/pytorch_model.bin\n","Saving model checkpoint to /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-130000\n","Configuration saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-130000/config.json\n","Model weights saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-130000/pytorch_model.bin\n","Saving model checkpoint to /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-140000\n","Configuration saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-140000/config.json\n","Model weights saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-140000/pytorch_model.bin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='160101' max='187175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [160101/187175 4:39:06 < 2:30:49, 2.99 it/s, Epoch 4.28/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>115000</td>\n","      <td>0.823800</td>\n","    </tr>\n","    <tr>\n","      <td>120000</td>\n","      <td>0.807500</td>\n","    </tr>\n","    <tr>\n","      <td>125000</td>\n","      <td>0.797500</td>\n","    </tr>\n","    <tr>\n","      <td>130000</td>\n","      <td>0.793000</td>\n","    </tr>\n","    <tr>\n","      <td>135000</td>\n","      <td>0.785600</td>\n","    </tr>\n","    <tr>\n","      <td>140000</td>\n","      <td>0.777800</td>\n","    </tr>\n","    <tr>\n","      <td>145000</td>\n","      <td>0.776000</td>\n","    </tr>\n","    <tr>\n","      <td>150000</td>\n","      <td>0.768200</td>\n","    </tr>\n","    <tr>\n","      <td>155000</td>\n","      <td>0.762700</td>\n","    </tr>\n","    <tr>\n","      <td>160000</td>\n","      <td>0.759100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-150000\n","Configuration saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-150000/config.json\n","Model weights saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-150000/pytorch_model.bin\n","Saving model checkpoint to /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-160000\n","Configuration saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-160000/config.json\n","Model weights saved in /content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-160000/pytorch_model.bin\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-bb2d8e567ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# trainer.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2199\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# trainer.save_model('/content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm')"],"metadata":{"id":"2N1Boyosyqi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CCzkwf-a3WRq"},"execution_count":null,"outputs":[]}]}