{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":736,"status":"ok","timestamp":1654179629790,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"K4qGssRjG0x3","outputId":"81d992bb-e9ba-44a2-c576-f33c181e71e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Jun  2 14:20:28 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    46W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2844,"status":"ok","timestamp":1654179632630,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"adYC61SwsXcp","outputId":"5e6b540c-d990-4c8d-8311-95dd6025effd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22089,"status":"ok","timestamp":1654179654716,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"xKp3fWhHG3xg","outputId":"e2b15b99-a4ae-4cdd-c604-a1327129ebf7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 55.2 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 67.2 MB/s \n","\u001b[K     |████████████████████████████████| 86 kB 6.0 MB/s \n","\u001b[K     |████████████████████████████████| 346 kB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 77.4 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 88.0 MB/s \n","\u001b[K     |████████████████████████████████| 86 kB 8.2 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 83.5 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 87.7 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 4.5 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 89.3 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 91.5 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 92.1 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 79 kB 3.6 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 30.6 MB/s \n","\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q transformers\n","!pip install -q datasets\n","!pip install -q sentence-transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHbEbk1FHIfE"},"outputs":[],"source":["import os, sys\n","import random\n","from pathlib import Path\n","from tqdm.notebook import tqdm\n","from typing import Dict\n","\n","\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","from datasets import load_metric\n","\n","from transformers import RobertaForMaskedLM, RobertaTokenizerFast, RobertaTokenizer\n","from transformers import LineByLineTextDataset, DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","from sentence_transformers import InputExample\n","from sentence_transformers import models, SentenceTransformer\n","from sentence_transformers import losses\n","from sentence_transformers.util import cos_sim\n","from sentence_transformers.evaluation import LabelAccuracyEvaluator\n","from sentence_transformers.losses.TripletLoss import TripletDistanceMetric"]},{"cell_type":"markdown","metadata":{"id":"gml80IveiAZp"},"source":["# Prepare Dataset"]},{"cell_type":"markdown","metadata":{"id":"Vv41Cq86h44G"},"source":["## Load Dataframe dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":16601,"status":"ok","timestamp":1654179677647,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"6ns3s8soHRjt","outputId":"6f4f21f6-d3a7-40a4-d2e8-ca982a57c3a2"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-d18b9d24-b10a-4055-bb22-f4a5b8a5ece5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>cell_id</th>\n","      <th>cell_type</th>\n","      <th>source</th>\n","      <th>rank</th>\n","      <th>ancestor_id</th>\n","      <th>parent_id</th>\n","      <th>pct_rank</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00001756c60be8</td>\n","      <td>1862f0a6</td>\n","      <td>code</td>\n","      <td># this python 3 environment comes with many he...</td>\n","      <td>0</td>\n","      <td>945aea18</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00001756c60be8</td>\n","      <td>2a9e43d6</td>\n","      <td>code</td>\n","      <td>import numpy as np import pandas as pd import ...</td>\n","      <td>2</td>\n","      <td>945aea18</td>\n","      <td>NaN</td>\n","      <td>0.034483</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00001756c60be8</td>\n","      <td>038b763d</td>\n","      <td>code</td>\n","      <td>import warnings warnings.filterwarnings('ignore')</td>\n","      <td>4</td>\n","      <td>945aea18</td>\n","      <td>NaN</td>\n","      <td>0.068966</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00001756c60be8</td>\n","      <td>2eefe0ef</td>\n","      <td>code</td>\n","      <td>matplotlib.rcparams.update({'font.size': 14})</td>\n","      <td>6</td>\n","      <td>945aea18</td>\n","      <td>NaN</td>\n","      <td>0.103448</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00001756c60be8</td>\n","      <td>0beab1cd</td>\n","      <td>code</td>\n","      <td>def evaluate_preds(train_true_values, train_pr...</td>\n","      <td>8</td>\n","      <td>945aea18</td>\n","      <td>NaN</td>\n","      <td>0.137931</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6055708</th>\n","      <td>fffe1d764579d5</td>\n","      <td>0d770d6b</td>\n","      <td>markdown</td>\n","      <td>removing the outliers</td>\n","      <td>43</td>\n","      <td>3c40bfa6</td>\n","      <td>NaN</td>\n","      <td>0.597222</td>\n","    </tr>\n","    <tr>\n","      <th>6055709</th>\n","      <td>fffe1d764579d5</td>\n","      <td>d45ddc62</td>\n","      <td>markdown</td>\n","      <td>dimensionality curse</td>\n","      <td>33</td>\n","      <td>3c40bfa6</td>\n","      <td>NaN</td>\n","      <td>0.458333</td>\n","    </tr>\n","    <tr>\n","      <th>6055710</th>\n","      <td>fffe1d764579d5</td>\n","      <td>1a63248d</td>\n","      <td>markdown</td>\n","      <td>bangalore house price prediction</td>\n","      <td>0</td>\n","      <td>3c40bfa6</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>6055711</th>\n","      <td>fffe1d764579d5</td>\n","      <td>a8ffc8b4</td>\n","      <td>markdown</td>\n","      <td>we have achieved accuracy in predicting the pr...</td>\n","      <td>69</td>\n","      <td>3c40bfa6</td>\n","      <td>NaN</td>\n","      <td>0.958333</td>\n","    </tr>\n","    <tr>\n","      <th>6055712</th>\n","      <td>fffe1d764579d5</td>\n","      <td>4e2d4c2d</td>\n","      <td>markdown</td>\n","      <td>data ingestion</td>\n","      <td>3</td>\n","      <td>3c40bfa6</td>\n","      <td>NaN</td>\n","      <td>0.041667</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6055713 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d18b9d24-b10a-4055-bb22-f4a5b8a5ece5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d18b9d24-b10a-4055-bb22-f4a5b8a5ece5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d18b9d24-b10a-4055-bb22-f4a5b8a5ece5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                     id   cell_id cell_type  \\\n","0        00001756c60be8  1862f0a6      code   \n","1        00001756c60be8  2a9e43d6      code   \n","2        00001756c60be8  038b763d      code   \n","3        00001756c60be8  2eefe0ef      code   \n","4        00001756c60be8  0beab1cd      code   \n","...                 ...       ...       ...   \n","6055708  fffe1d764579d5  0d770d6b  markdown   \n","6055709  fffe1d764579d5  d45ddc62  markdown   \n","6055710  fffe1d764579d5  1a63248d  markdown   \n","6055711  fffe1d764579d5  a8ffc8b4  markdown   \n","6055712  fffe1d764579d5  4e2d4c2d  markdown   \n","\n","                                                    source rank ancestor_id  \\\n","0        # this python 3 environment comes with many he...    0    945aea18   \n","1        import numpy as np import pandas as pd import ...    2    945aea18   \n","2        import warnings warnings.filterwarnings('ignore')    4    945aea18   \n","3            matplotlib.rcparams.update({'font.size': 14})    6    945aea18   \n","4        def evaluate_preds(train_true_values, train_pr...    8    945aea18   \n","...                                                    ...  ...         ...   \n","6055708                              removing the outliers   43    3c40bfa6   \n","6055709                               dimensionality curse   33    3c40bfa6   \n","6055710                   bangalore house price prediction    0    3c40bfa6   \n","6055711  we have achieved accuracy in predicting the pr...   69    3c40bfa6   \n","6055712                                     data ingestion    3    3c40bfa6   \n","\n","        parent_id  pct_rank  \n","0             NaN       0.0  \n","1             NaN  0.034483  \n","2             NaN  0.068966  \n","3             NaN  0.103448  \n","4             NaN  0.137931  \n","...           ...       ...  \n","6055708       NaN  0.597222  \n","6055709       NaN  0.458333  \n","6055710       NaN       0.0  \n","6055711       NaN  0.958333  \n","6055712       NaN  0.041667  \n","\n","[6055713 rows x 8 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_df = pd.read_pickle('/content/drive/MyDrive/NLP/AI4Code/dataset/exp_5/clean_train_dataset.pkl')\n","train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":1297,"status":"ok","timestamp":1654179678937,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"8-L2ZS4a3vms","outputId":"90c2252d-23ec-46d3-d5f8-4f0feba75f8e"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-3f84ff9c-565e-4c72-b4e5-c098b367b426\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>cell_id</th>\n","      <th>cell_type</th>\n","      <th>source</th>\n","      <th>rank</th>\n","      <th>ancestor_id</th>\n","      <th>parent_id</th>\n","      <th>pct_rank</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0002115f48f982</td>\n","      <td>18281c6c</td>\n","      <td>code</td>\n","      <td>import numpy as np # linear algebra import pan...</td>\n","      <td>1</td>\n","      <td>272b483a</td>\n","      <td>NaN</td>\n","      <td>0.111111</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0002115f48f982</td>\n","      <td>e3b6b115</td>\n","      <td>code</td>\n","      <td>df = pd.read_csv('../input/metadata_train.csv'...</td>\n","      <td>2</td>\n","      <td>272b483a</td>\n","      <td>NaN</td>\n","      <td>0.222222</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0002115f48f982</td>\n","      <td>4a044c54</td>\n","      <td>code</td>\n","      <td>df.head()</td>\n","      <td>3</td>\n","      <td>272b483a</td>\n","      <td>NaN</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0002115f48f982</td>\n","      <td>365fe576</td>\n","      <td>code</td>\n","      <td>#let's check if targets are consistent within ...</td>\n","      <td>4</td>\n","      <td>272b483a</td>\n","      <td>NaN</td>\n","      <td>0.444444</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0002115f48f982</td>\n","      <td>a3188e54</td>\n","      <td>code</td>\n","      <td>sns.countplot(x='target',data=targets) # it sh...</td>\n","      <td>5</td>\n","      <td>272b483a</td>\n","      <td>NaN</td>\n","      <td>0.555556</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>314928</th>\n","      <td>fff06cc23780af</td>\n","      <td>f8135651</td>\n","      <td>markdown</td>\n","      <td>lowering the case</td>\n","      <td>14</td>\n","      <td>7b4c5375</td>\n","      <td>NaN</td>\n","      <td>0.17284</td>\n","    </tr>\n","    <tr>\n","      <th>314929</th>\n","      <td>fff06cc23780af</td>\n","      <td>b61ba8ec</td>\n","      <td>markdown</td>\n","      <td>testing the model on test set</td>\n","      <td>60</td>\n","      <td>7b4c5375</td>\n","      <td>NaN</td>\n","      <td>0.740741</td>\n","    </tr>\n","    <tr>\n","      <th>314930</th>\n","      <td>fff06cc23780af</td>\n","      <td>e98b7e0d</td>\n","      <td>markdown</td>\n","      <td>the aim of this notebook is to predict if twee...</td>\n","      <td>2</td>\n","      <td>7b4c5375</td>\n","      <td>NaN</td>\n","      <td>0.024691</td>\n","    </tr>\n","    <tr>\n","      <th>314931</th>\n","      <td>fff06cc23780af</td>\n","      <td>f31fa490</td>\n","      <td>markdown</td>\n","      <td>having created this notebook from scratch star...</td>\n","      <td>80</td>\n","      <td>7b4c5375</td>\n","      <td>NaN</td>\n","      <td>0.987654</td>\n","    </tr>\n","    <tr>\n","      <th>314932</th>\n","      <td>fff06cc23780af</td>\n","      <td>d50a78be</td>\n","      <td>markdown</td>\n","      <td>building the vocabulary. in another approach w...</td>\n","      <td>37</td>\n","      <td>7b4c5375</td>\n","      <td>NaN</td>\n","      <td>0.45679</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>314933 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f84ff9c-565e-4c72-b4e5-c098b367b426')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3f84ff9c-565e-4c72-b4e5-c098b367b426 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3f84ff9c-565e-4c72-b4e5-c098b367b426');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    id   cell_id cell_type  \\\n","0       0002115f48f982  18281c6c      code   \n","1       0002115f48f982  e3b6b115      code   \n","2       0002115f48f982  4a044c54      code   \n","3       0002115f48f982  365fe576      code   \n","4       0002115f48f982  a3188e54      code   \n","...                ...       ...       ...   \n","314928  fff06cc23780af  f8135651  markdown   \n","314929  fff06cc23780af  b61ba8ec  markdown   \n","314930  fff06cc23780af  e98b7e0d  markdown   \n","314931  fff06cc23780af  f31fa490  markdown   \n","314932  fff06cc23780af  d50a78be  markdown   \n","\n","                                                   source rank ancestor_id  \\\n","0       import numpy as np # linear algebra import pan...    1    272b483a   \n","1       df = pd.read_csv('../input/metadata_train.csv'...    2    272b483a   \n","2                                               df.head()    3    272b483a   \n","3       #let's check if targets are consistent within ...    4    272b483a   \n","4       sns.countplot(x='target',data=targets) # it sh...    5    272b483a   \n","...                                                   ...  ...         ...   \n","314928                                  lowering the case   14    7b4c5375   \n","314929                      testing the model on test set   60    7b4c5375   \n","314930  the aim of this notebook is to predict if twee...    2    7b4c5375   \n","314931  having created this notebook from scratch star...   80    7b4c5375   \n","314932  building the vocabulary. in another approach w...   37    7b4c5375   \n","\n","       parent_id  pct_rank  \n","0            NaN  0.111111  \n","1            NaN  0.222222  \n","2            NaN  0.333333  \n","3            NaN  0.444444  \n","4            NaN  0.555556  \n","...          ...       ...  \n","314928       NaN   0.17284  \n","314929       NaN  0.740741  \n","314930       NaN  0.024691  \n","314931       NaN  0.987654  \n","314932       NaN   0.45679  \n","\n","[314933 rows x 8 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["val_df = pd.read_pickle('/content/drive/MyDrive/NLP/AI4Code/dataset/exp_5/clean_val_dataset.pkl')\n","val_df"]},{"cell_type":"markdown","metadata":{"id":"8JLKSSrriDad"},"source":["## Create cellid--source dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGvyBBJQHxvT"},"outputs":[],"source":["train_dict_cellid_source = dict(zip(train_df['cell_id'].values, train_df['source'].values))\n","val_dict_cellid_source = dict(zip(val_df['cell_id'].values, val_df['source'].values))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvMjRIlJH_Gl"},"outputs":[],"source":["def generate_triplet(df):\n","    triplets = []\n","    count = 0\n","\n","    for id, df_tmp in tqdm(df.groupby('id')):\n","        df_tmp_markdown = df_tmp[df_tmp['cell_type'] == 'markdown']\n","        df_tmp_code = df_tmp[df_tmp['cell_type'] == 'code']\n","\n","        df_tmp_code_rank = df_tmp_code['rank'].values\n","        df_tmp_code_cellid = df_tmp_code['cell_id'].values\n","\n","        for cell_id, rank in df_tmp_markdown[['cell_id', 'rank']].values:\n","            labels = np.array([r == (rank+1) for r in df_tmp_code_rank]).astype('int')\n","\n","            pos_position = np.where(labels == 1)[0]\n","\n","            if len(pos_position):\n","                pos_position = pos_position[0]\n","                pos_cellid = df_tmp_code_cellid[pos_position]\n","                pos_label = labels[pos_position]\n","                # triplets.append([cell_id, pos_cellid, int(pos_label)])\n","\n","                neg_positions = [x for x in range(0, len(labels)) if x != pos_position]\n","\n","                if len(neg_positions):\n","                    # neg_ranks = df_tmp_code_rank[neg_positions].tolist()\n","                    # fil = list(filter(lambda x: x > rank, neg_ranks))\n","                    # if len(fil):\n","                    #     hard_neg_rank = min(fil)\n","                    #     hard_neg_cellid = df_tmp_code.loc[df_tmp_code['rank'] == hard_neg_rank, 'cell_id'].values[0]\n","                    #     hard_neg_label = 0\n","                    #     triplets.append([cell_id, pos_cellid, hard_neg_cellid])\n","                    # else:\n","                    #     neg_position = random.choice(neg_positions)\n","                    #     neg_cellid = df_tmp_code_cellid[neg_position]\n","                    #     triplets.append([cell_id, pos_cellid, neg_cellid])\n","\n","                    neg_positions = random.choices(neg_positions, k=5)\n","                    neg_cellids = df_tmp_code_cellid[neg_positions]\n","                    for neg_cellid in neg_cellids:\n","                        triplets.append([cell_id, pos_cellid, neg_cellid])\n","    \n","    return triplets"]},{"cell_type":"markdown","metadata":{"id":"9SvsVfoWiNYI"},"source":["## Take fraction of dataset for test running"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZIF7AptKwOu"},"outputs":[],"source":["# train_df = train_df.loc[:600000]\n","# train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvB6m-7b34Yt"},"outputs":[],"source":["# val_df = val_df.loc[:30000]\n","# val_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["69f38407f35d4b81ae166137bfd6b118","9a24b9c759824dd79e0f3c8b78cdf66e","791f1608bbb343ee8d945527cd011c8f","1f9fb7df7dd54d9d873ff84c781e229c","8444389decdb419db5d1ebb0821ed98a","656f80bd641240ec8bfea4f6b4ea36ba","fc44bec81e6d4867be4099f231bd200a","735d368562db474e8fe1bd9ddd655ed5","b4c894a1ea3f4415a2f6f5cdb899f2c0","b5c3a1a99c5b4f6f93120a11653ed7d8","c9e2a8c3feca485899fb1c349320ed6a","837c97b59f2948af9239fd42f590f331","2c1cb00711f3480d8a30ad932b05640f","df2a5981a959403593ffbb29937ef48c","629833cd6c10443b8f3d6d17a6b14eb8","48d5c4b92bd74ea7b9a18193c9cd6288","b3e361245d274626b362ad35e890825e","450380363ad64891a40eb8f7b284a556","4a43c216a17c40ec8a630e207a8b1ede","ec01c21e847845e8ac81656425afe5a1","c00ba20fce024a9892aa1aef650b34d3","357fb25518424bb1a77e90d6b7ebeaa4"]},"executionInfo":{"elapsed":265997,"status":"ok","timestamp":1654179947962,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"_1Y6KMgjK6jH","outputId":"90834319-e0f0-45f1-e934-c14569be9c48"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69f38407f35d4b81ae166137bfd6b118","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/132361 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"837c97b59f2948af9239fd42f590f331","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6895 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_triplets = generate_triplet(train_df)\n","val_triplets = generate_triplet(val_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1654179947963,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"YIjM4gU8DHfh","outputId":"96a298ce-63be-4726-f52c-5537bc4c6e29"},"outputs":[{"data":{"text/plain":["[['21616367', '86497fe1', '781bbf3c'],\n"," ['21616367', '86497fe1', '2a9e43d6'],\n"," ['21616367', '86497fe1', '9a78ab76'],\n"," ['21616367', '86497fe1', 'bd94f005'],\n"," ['21616367', '86497fe1', '1862f0a6'],\n"," ['fcb6792d', '5bf9ca51', 'dd0c804a'],\n"," ['fcb6792d', '5bf9ca51', '62638fba'],\n"," ['fcb6792d', '5bf9ca51', '86497fe1'],\n"," ['fcb6792d', '5bf9ca51', '781bbf3c'],\n"," ['fcb6792d', '5bf9ca51', '06365725'],\n"," ['63c26fa2', '62638fba', '5bf9ca51'],\n"," ['63c26fa2', '62638fba', '9a78ab76'],\n"," ['63c26fa2', '62638fba', '0beab1cd'],\n"," ['63c26fa2', '62638fba', 'f5504853'],\n"," ['63c26fa2', '62638fba', 'ebe125d5'],\n"," ['4bb2e30a', 'bd94f005', '6b5664c7'],\n"," ['4bb2e30a', 'bd94f005', '8ca8392c'],\n"," ['4bb2e30a', 'bd94f005', '038b763d'],\n"," ['4bb2e30a', 'bd94f005', '0e7c906e'],\n"," ['4bb2e30a', 'bd94f005', '8ca8392c'],\n"," ['a6357f7e', 'ff7c44ed', '86497fe1'],\n"," ['a6357f7e', 'ff7c44ed', '06365725'],\n"," ['a6357f7e', 'ff7c44ed', '5bf9ca51'],\n"," ['a6357f7e', 'ff7c44ed', '6b5664c7'],\n"," ['a6357f7e', 'ff7c44ed', '9a78ab76'],\n"," ['45082c89', '781bbf3c', '2a9e43d6'],\n"," ['45082c89', '781bbf3c', '59959af5'],\n"," ['45082c89', '781bbf3c', '1862f0a6'],\n"," ['45082c89', '781bbf3c', 'ebe125d5'],\n"," ['45082c89', '781bbf3c', '2eefe0ef'],\n"," ['77e56113', '2eefe0ef', 'e2c8e725'],\n"," ['77e56113', '2eefe0ef', '86497fe1'],\n"," ['77e56113', '2eefe0ef', '8522781a'],\n"," ['77e56113', '2eefe0ef', '9f50dca0'],\n"," ['77e56113', '2eefe0ef', '6b5664c7'],\n"," ['448eb224', '2a9e43d6', '038b763d'],\n"," ['448eb224', '2a9e43d6', 'f5504853'],\n"," ['448eb224', '2a9e43d6', '9a78ab76'],\n"," ['448eb224', '2a9e43d6', '76512d50'],\n"," ['448eb224', '2a9e43d6', '1862f0a6'],\n"," ['032e2820', 'a98c5d9f', 'ebe125d5'],\n"," ['032e2820', 'a98c5d9f', '781bbf3c'],\n"," ['032e2820', 'a98c5d9f', '8ca8392c'],\n"," ['032e2820', 'a98c5d9f', 'ff7c44ed'],\n"," ['032e2820', 'a98c5d9f', 'ff7c44ed'],\n"," ['8554b284', '59959af5', 'e2c8e725'],\n"," ['8554b284', '59959af5', '2a9e43d6'],\n"," ['8554b284', '59959af5', 'dd0c804a'],\n"," ['8554b284', '59959af5', 'f5504853'],\n"," ['8554b284', '59959af5', 'bb69e88c'],\n"," ['ac301a84', '0e7c906e', '8ca8392c'],\n"," ['ac301a84', '0e7c906e', 'e2c8e725'],\n"," ['ac301a84', '0e7c906e', '80151ab7'],\n"," ['ac301a84', '0e7c906e', '9a78ab76'],\n"," ['ac301a84', '0e7c906e', '2a9e43d6'],\n"," ['23705731', 'ebe125d5', 'bd94f005'],\n"," ['23705731', 'ebe125d5', '5bf9ca51'],\n"," ['23705731', 'ebe125d5', '17ec3fc4'],\n"," ['23705731', 'ebe125d5', 'ff7c44ed'],\n"," ['23705731', 'ebe125d5', 'e2c8e725'],\n"," ['1496beaf', '8ca8392c', '0e7c906e'],\n"," ['1496beaf', '8ca8392c', '6b5664c7'],\n"," ['1496beaf', '8ca8392c', '86497fe1'],\n"," ['1496beaf', '8ca8392c', 'a98c5d9f'],\n"," ['1496beaf', '8ca8392c', '23783525'],\n"," ['2e1a5949', '80151ab7', 'ebe125d5'],\n"," ['2e1a5949', '80151ab7', 'f5504853'],\n"," ['2e1a5949', '80151ab7', '23783525'],\n"," ['2e1a5949', '80151ab7', '5bf9ca51'],\n"," ['2e1a5949', '80151ab7', '9a78ab76'],\n"," ['7e2f170a', '038b763d', 'd9dced8b'],\n"," ['7e2f170a', '038b763d', '9f50dca0'],\n"," ['7e2f170a', '038b763d', '1862f0a6'],\n"," ['7e2f170a', '038b763d', '76512d50'],\n"," ['7e2f170a', '038b763d', '76512d50'],\n"," ['bfbde93e', '8522781a', '0beab1cd'],\n"," ['bfbde93e', '8522781a', '9f50dca0'],\n"," ['bfbde93e', '8522781a', 'ebe125d5'],\n"," ['bfbde93e', '8522781a', '9f50dca0'],\n"," ['bfbde93e', '8522781a', '6b5664c7'],\n"," ['915643b3', 'f5504853', '76512d50'],\n"," ['915643b3', 'f5504853', 'dd0c804a'],\n"," ['915643b3', 'f5504853', 'd9dced8b'],\n"," ['915643b3', 'f5504853', '0e7c906e'],\n"," ['915643b3', 'f5504853', 'dd0c804a'],\n"," ['8ffe0b25', '9a78ab76', '2a9e43d6'],\n"," ['8ffe0b25', '9a78ab76', '8522781a'],\n"," ['8ffe0b25', '9a78ab76', '9f50dca0'],\n"," ['8ffe0b25', '9a78ab76', '781bbf3c'],\n"," ['8ffe0b25', '9a78ab76', 'ebe125d5'],\n"," ['b69a4f9b', '17ec3fc4', '2eefe0ef'],\n"," ['b69a4f9b', '17ec3fc4', 'ebe125d5'],\n"," ['b69a4f9b', '17ec3fc4', '6b5664c7'],\n"," ['b69a4f9b', '17ec3fc4', 'bd94f005'],\n"," ['b69a4f9b', '17ec3fc4', '06365725'],\n"," ['c3ce0945', 'e2c8e725', '2eefe0ef'],\n"," ['c3ce0945', 'e2c8e725', '5bf9ca51'],\n"," ['c3ce0945', 'e2c8e725', '8ca8392c'],\n"," ['c3ce0945', 'e2c8e725', '9a78ab76'],\n"," ['c3ce0945', 'e2c8e725', 'a98c5d9f']]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_triplets[:100]"]},{"cell_type":"markdown","metadata":{"id":"6rrSCYywids5"},"source":["## Define custom Dataset for Huggingface Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABuJlcLaF3Sg"},"outputs":[],"source":["train_samples = []\n","for triplet in train_triplets:\n","    markdown_text = train_dict_cellid_source[triplet[0]]\n","    pos_code_text = train_dict_cellid_source[triplet[1]]\n","    neg_code_text = train_dict_cellid_source[triplet[2]]\n","    train_samples.append(InputExample(\n","        texts=[markdown_text, pos_code_text, neg_code_text]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqP6oy4ZIDvc"},"outputs":[],"source":["val_samples = []\n","for triplet in val_triplets:\n","    markdown_text = val_dict_cellid_source[triplet[0]]\n","    pos_code_text = val_dict_cellid_source[triplet[1]]\n","    neg_code_text = val_dict_cellid_source[triplet[2]]\n","    val_samples.append(InputExample(\n","        texts=[markdown_text, pos_code_text, neg_code_text]))"]},{"cell_type":"markdown","metadata":{"id":"U2j57Zcwiz2K"},"source":["## Training dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XaVX_9uVi3FP"},"outputs":[],"source":["BATCH_SIZE = 48\n","\n","train_dataloader = DataLoader(train_samples, batch_size=BATCH_SIZE, shuffle=True,\n","                              num_workers=0, drop_last=False)\n","\n","val_dataloader = DataLoader(val_samples, batch_size=BATCH_SIZE, shuffle=False,\n","                              num_workers=0, drop_last=False)"]},{"cell_type":"markdown","metadata":{"id":"uYO0PJ6LjcnS"},"source":["# Sentence Transformer Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7625,"status":"ok","timestamp":1654179979254,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"},"user_tz":-420},"id":"GLpeph1ook6W","outputId":"6ccadc8d-07ce-4eda-a9f6-f7754b02e717"},"outputs":[{"data":{"text/plain":["SentenceTransformer(\n","  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: RobertaModel \n","  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# bert = models.Transformer(\"/content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_mlm/checkpoint-160000\", max_seq_length=256)\n","# pooler = models.Pooling(\n","#     bert.get_word_embedding_dimension(),\n","#     pooling_mode_mean_tokens=True,\n","# )\n","\n","# model = SentenceTransformer(modules=[bert, pooler])\n","model = SentenceTransformer('/content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_task/trial_4/200000')\n","model"]},{"cell_type":"markdown","metadata":{"id":"xz0SbZlwPVOp"},"source":["## Freeze some layer for faster training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvLdnzCTQOu2"},"outputs":[],"source":["# for name, module in model.named_modules():\n","#     print(name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SPjYd5yRPUrX"},"outputs":[],"source":["# model[0].auto_model.encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vaejPxxKQYuW"},"outputs":[],"source":["# for param in model[0].auto_model.encoder.parameters():\n","#     param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"ZCsJHv8GI93Q"},"source":["# Loss function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWXUutGGI_uN"},"outputs":[],"source":["loss = losses.MultipleNegativesRankingLoss(model=model)"]},{"cell_type":"markdown","metadata":{"id":"zDA9DUB4jrlz"},"source":["# Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UDuOD-7C9TCy"},"outputs":[],"source":["from sentence_transformers.evaluation import TripletEvaluator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlpYGoXH72zp"},"outputs":[],"source":["evaluator = TripletEvaluator.from_input_examples(val_samples)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":481,"referenced_widgets":["a4f1e135df1c4e20b48d77108edef952","fa65bfd4c4d74eb9846050097e8d40d0","3ef71266edda4334be9aee90c5d3beb6","03235d539a6947e5bed15696f247aa15","88d98fa7927445fb887473045227eca3","c83cac4594034d8b8c658c73409e2b0a","baa1b81a50f34810834797a386edda63","ff4400811bc0435dade6de22fd7735a8","37131e57c9804376a8f736cf943df3c4","c062564330dc4cd7bb7af5ed7c88eb5e","ae233124bef34e769d2762cecaabde48","7df4306ad3b447aeb0ac5bddccef16cd","1650f94f84234ef1b83ad9511411f3c3","4140df8857ae416981f345870894b746","ec82a75b780a40a697b4ff697f333ac2","e2a59965d2ea4f139f735af0cf55baa0","6a0614250e884456b1d62ff3a03ced8f","a98ab93286d047a59f09ee4551110c37","95b2b0fbc7874f7eaaae135d2037cf0a","d943cdbbb0404f90a82de5b883a0187a","a7e94d0a6fdc4ac494fca73c0c6d7479","d088578469164c2da7405070f3bafbe4"]},"id":"3GAyf9GukhMP","executionInfo":{"status":"error","timestamp":1654242991874,"user_tz":-420,"elapsed":20414537,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}},"outputId":"24264854-7518-4253-c3b4-9947c71cb8b6"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4f1e135df1c4e20b48d77108edef952","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7df4306ad3b447aeb0ac5bddccef16cd","version_major":2,"version_minor":0},"text/plain":["Iteration:   0%|          | 0/156370 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-9f755503f070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcheckpoint_save_total_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0muse_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_during_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m#No evaluator, but output path: save final model version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_eval_during_training\u001b[0;34m(self, evaluator, output_path, save_best_model, epoch, steps, callback)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/evaluation/TripletEvaluator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m     89\u001b[0m         )\n\u001b[1;32m     90\u001b[0m         embeddings_positives = model.encode(\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositives\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         )\n\u001b[1;32m     93\u001b[0m         embeddings_negatives = model.encode(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'token_embeddings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtrans_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         )\n\u001b[1;32m    859\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 )\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         )\n\u001b[1;32m    416\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    345\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_buffers'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0m_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_buffers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["epochs = 1\n","# warmup_steps = int(len(train_dataloader) * epochs * 0.1)\n","warmup_steps = 0\n","\n","model.fit(\n","    train_objectives=[(train_dataloader, loss)],\n","    epochs=epochs,\n","    evaluator=evaluator,\n","    evaluation_steps=30000,\n","    warmup_steps=warmup_steps,\n","    output_path='/content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_task/trial_6',\n","    checkpoint_path='/content/drive/MyDrive/NLP/AI4Code/pretrained/exp_5/pretrained_task/trial_6',\n","    optimizer_params={'lr': 5e-6},\n","    checkpoint_save_steps=50000,\n","    checkpoint_save_total_limit=2,\n","    use_amp=True,\n","    show_progress_bar=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RfrtdG8iucWh","executionInfo":{"status":"aborted","timestamp":1654242991876,"user_tz":-420,"elapsed":2,"user":{"displayName":"Cong Phu Nguyen","userId":"16550869234069995488"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"MNR_loss_task_training.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03235d539a6947e5bed15696f247aa15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c062564330dc4cd7bb7af5ed7c88eb5e","placeholder":"​","style":"IPY_MODEL_ae233124bef34e769d2762cecaabde48","value":" 0/1 [17:29:54&lt;?, ?it/s]"}},"1650f94f84234ef1b83ad9511411f3c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a0614250e884456b1d62ff3a03ced8f","placeholder":"​","style":"IPY_MODEL_a98ab93286d047a59f09ee4551110c37","value":"Iteration: 100%"}},"1f9fb7df7dd54d9d873ff84c781e229c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5c3a1a99c5b4f6f93120a11653ed7d8","placeholder":"​","style":"IPY_MODEL_c9e2a8c3feca485899fb1c349320ed6a","value":" 132361/132361 [04:10&lt;00:00, 510.86it/s]"}},"2c1cb00711f3480d8a30ad932b05640f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3e361245d274626b362ad35e890825e","placeholder":"​","style":"IPY_MODEL_450380363ad64891a40eb8f7b284a556","value":"100%"}},"357fb25518424bb1a77e90d6b7ebeaa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37131e57c9804376a8f736cf943df3c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ef71266edda4334be9aee90c5d3beb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff4400811bc0435dade6de22fd7735a8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37131e57c9804376a8f736cf943df3c4","value":0}},"4140df8857ae416981f345870894b746":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95b2b0fbc7874f7eaaae135d2037cf0a","max":156370,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d943cdbbb0404f90a82de5b883a0187a","value":156370}},"450380363ad64891a40eb8f7b284a556":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48d5c4b92bd74ea7b9a18193c9cd6288":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a43c216a17c40ec8a630e207a8b1ede":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"629833cd6c10443b8f3d6d17a6b14eb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c00ba20fce024a9892aa1aef650b34d3","placeholder":"​","style":"IPY_MODEL_357fb25518424bb1a77e90d6b7ebeaa4","value":" 6895/6895 [00:13&lt;00:00, 529.75it/s]"}},"656f80bd641240ec8bfea4f6b4ea36ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69f38407f35d4b81ae166137bfd6b118":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a24b9c759824dd79e0f3c8b78cdf66e","IPY_MODEL_791f1608bbb343ee8d945527cd011c8f","IPY_MODEL_1f9fb7df7dd54d9d873ff84c781e229c"],"layout":"IPY_MODEL_8444389decdb419db5d1ebb0821ed98a"}},"6a0614250e884456b1d62ff3a03ced8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"735d368562db474e8fe1bd9ddd655ed5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"791f1608bbb343ee8d945527cd011c8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_735d368562db474e8fe1bd9ddd655ed5","max":132361,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4c894a1ea3f4415a2f6f5cdb899f2c0","value":132361}},"7df4306ad3b447aeb0ac5bddccef16cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1650f94f84234ef1b83ad9511411f3c3","IPY_MODEL_4140df8857ae416981f345870894b746","IPY_MODEL_ec82a75b780a40a697b4ff697f333ac2"],"layout":"IPY_MODEL_e2a59965d2ea4f139f735af0cf55baa0"}},"837c97b59f2948af9239fd42f590f331":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c1cb00711f3480d8a30ad932b05640f","IPY_MODEL_df2a5981a959403593ffbb29937ef48c","IPY_MODEL_629833cd6c10443b8f3d6d17a6b14eb8"],"layout":"IPY_MODEL_48d5c4b92bd74ea7b9a18193c9cd6288"}},"8444389decdb419db5d1ebb0821ed98a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88d98fa7927445fb887473045227eca3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95b2b0fbc7874f7eaaae135d2037cf0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a24b9c759824dd79e0f3c8b78cdf66e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_656f80bd641240ec8bfea4f6b4ea36ba","placeholder":"​","style":"IPY_MODEL_fc44bec81e6d4867be4099f231bd200a","value":"100%"}},"a4f1e135df1c4e20b48d77108edef952":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa65bfd4c4d74eb9846050097e8d40d0","IPY_MODEL_3ef71266edda4334be9aee90c5d3beb6","IPY_MODEL_03235d539a6947e5bed15696f247aa15"],"layout":"IPY_MODEL_88d98fa7927445fb887473045227eca3"}},"a7e94d0a6fdc4ac494fca73c0c6d7479":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a98ab93286d047a59f09ee4551110c37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae233124bef34e769d2762cecaabde48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3e361245d274626b362ad35e890825e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4c894a1ea3f4415a2f6f5cdb899f2c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5c3a1a99c5b4f6f93120a11653ed7d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baa1b81a50f34810834797a386edda63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c00ba20fce024a9892aa1aef650b34d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c062564330dc4cd7bb7af5ed7c88eb5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c83cac4594034d8b8c658c73409e2b0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9e2a8c3feca485899fb1c349320ed6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d088578469164c2da7405070f3bafbe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d943cdbbb0404f90a82de5b883a0187a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df2a5981a959403593ffbb29937ef48c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a43c216a17c40ec8a630e207a8b1ede","max":6895,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec01c21e847845e8ac81656425afe5a1","value":6895}},"e2a59965d2ea4f139f735af0cf55baa0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec01c21e847845e8ac81656425afe5a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec82a75b780a40a697b4ff697f333ac2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7e94d0a6fdc4ac494fca73c0c6d7479","placeholder":"​","style":"IPY_MODEL_d088578469164c2da7405070f3bafbe4","value":" 156370/156370 [17:22:10&lt;00:00,  2.74it/s]"}},"fa65bfd4c4d74eb9846050097e8d40d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c83cac4594034d8b8c658c73409e2b0a","placeholder":"​","style":"IPY_MODEL_baa1b81a50f34810834797a386edda63","value":"Epoch:   0%"}},"fc44bec81e6d4867be4099f231bd200a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff4400811bc0435dade6de22fd7735a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}